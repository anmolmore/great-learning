Neural Networks -
1. Whether we use output numbers or probabilites in backpropagation ?
2. Tensorflow ==> 





Chatbots - https://web.njit.edu/~ronkowit/eliza.html



K Mode
Cross validation in imbalanced datasets

Threshold identification for imbalanced dataset -
https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/
https://www.scikit-yb.org/en/latest/api/classifier/rocauc.html#multi-class-rocauc-curves

PCA and model selection -
https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_refit_callable.html#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py

Grid Search vs Random Search which is better (Highly debatable) - 
https://stats.stackexchange.com/questions/160479/practical-hyperparameter-optimization-random-vs-grid-search

To classify a new instance we need to calculate information about
2 normal distributions
3 normal distributions
4 normal distributions
6 normal distributions






K Means --> Try Gaussian Mixture Models











Week 4 -->
https://towardsdatascience.com/understanding-support-vector-machine-part-2-kernel-trick-mercers-theorem-e1e6848c6c4d
https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
https://scikit-learn.org/stable/modules/svm.html


Support Vector Machine Regression 3D - http://www.semspirit.com/artificial-intelligence/machine-learning/regression/support-vector-regression/support-vector-regression-in-r/



Scaling in SVM ?
KNN and svm

Good blog - https://towardsdatascience.com/support-vector-machine-simply-explained-fee28eba5496

Type I and Type II Error - https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/error-probabilities-power/e/type-i-error-type-ii-error-powerx




--> Cross Validation
---> Fast Model
--> 



Ensemble - 
https://dataaspirant.com/ensemble-methods-bagging-vs-boosting-difference/
https://medium.com/fintechexplained/bagging-vs-boosting-in-machine-learning-8d7512d782e0


Creating CAT Models - https://medium.com/@aswalin?p=7cdef669aeed
Difference between XGBoost and GBM - https://datascience.stackexchange.com/questions/16904/gbm-vs-xgboost-key-differences

Difference between XGBoost, CATBoost, AdaBoost - https://www.kdnuggets.com/2018/03/catboost-vs-light-gbm-vs-xgboost.html
https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/



Unsupervised Learning :
	- K Means :
		- https://www.baeldung.com/java-k-means-clustering-algorithm
		
		
Oversampling :
	https://imbalanced-learn.org/stable/auto_examples/combine/plot_comparison_combine.html#sphx-glr-download-auto-examples-combine-plot-comparison-combine-py
	
	
	
	
1. Target balancing -->
    - undersampling vs. oversampling, 
    - before or after train test splitting, 
    - code example, if after train-test split: what to use for test and train sets because we can only enter two variables X_ros and Y_ros
2. Cross-validation --> 
   - example of code and explanation
3. GridSearchCV -->
   - code example, 
   - how to get best parameters, 
   - how to get list of n_neighbors and test_scores
4. Data Pipelines
		
